---
title: "AI 용어사전"
description: "［ A ］        ※ ACM (미국계산기학회)  ACM은 \"Association for Computing Machinery\"의 약자로, 컴퓨터 과학 분야에서 세계적으로 유명한 학술 및 전문 기술 기관입니다.        ※ Activation Function..."
id: "C136"
no: 136
order: 136
category: "ai"
subCategory: "glossary"
tags: ["AI", "용어", "사전", "인공지능", "glossary"]
created: "2025-04-04T02:13:22.374Z"
updated: "2025-05-22T04:39:11.840Z"
featured: true
draft: true
hasChildren: false
elementCount: 1180
childCount: 0
slug: "C136"
---

## ［ A ］



### ※ ACM (미국계산기학회)

ACM은 "Association for Computing Machinery"의 약자로, 컴퓨터 과학 분야에서 세계적으로 유명한 학술 및 전문 기술 기관입니다.



### ※ Activation Function (활성화 함수)

활성화 함수는 인공신경망에서 입력값을 출력값으로 바꾸어서 전달해주는 신경망속 함수들을 의미합니다.



### ※ AGI (인공 일반 지능)

AGI는 Artificial General Intelligence의 약자로 인간과 유사한 수준의 다양한 인지 작업을 수행하고 다양한 도메인에서 학습하고 적용할 수 있는 

능력을 갖춘 컴퓨터 시스템을 지칭합니다.



### ※ AI (인공지능)

AI는 Artificial Intelligence의 약자로 컴퓨터 프로그램이 인간의 지능과 유사한 지능을 가지고 어떠한 작업을 수행하도록하는 기술을 의미합니다.



### ※ AI alignment (AI 정렬)

안전이나 예절 등 모델이 일련의 가치를 지키도록 훈련하는 것을 의미



### ※ AI assurance (AI 보증)

인공지능 시스템이 여러 방면에서 신뢰성, 안정성, 윤리성 등을 보장할 수 있는지 확인하는 일련의 기술 및 프로세스



### ※ AI Bias (인공지능 편향)

AI 편향(AI Bias)은 인공지능 시스템이 학습하는 데이터, 알고리즘 설계, 또는 개발 과정에서의 인간의 편견이 반영되어 특정 그룹이나 개인에 대해 체계적으로 불공정하거나 차별적인 결과를 나타내는 현상을 의미



### ※ AICC (AI Contact Center)

음성 인식(STT), 자연어 처리(NLP), 음성 합성(TTS) 등의 인공지능(AI) 기술을 활용하여 컨택센터의 업무를 효율적이고 창의적으로 수행할 수 있도록 도와주는 서비스



### ※ AI Courseware (AI 코스웨어)

AI 코스웨어는 인공지능(AI) 기술을 교육에 접목한 학습 소프트웨어를 의미합니다.



### ※ AI Data Center (AI 데이터센터)

고속 입출력에 특화된 고대역폭 메모리(HBM, High Bandwidth Memory), 대규모 연산에 적합한 그래픽 처리장치(GPU, Graphic Processing Unit)와 같이

AI가 요구하는 대량의 데이터를 빠르게 처리할 수 있는 고성능 컴퓨팅 자원을 탑재하고, 고효율 냉각 시스템 및 전력 시스템을 갖춘 데이터센터



### ※ AI Ethics (AI윤리)

AI윤리는 인공지능의 발전으로 인해 인간의 권리와 자유, 사회적 가치와 도덕적 원칙 등을 침해하지 않도록 제약을 두고 AI가 지켜야할 윤리를 말합니다.



### ※ Algorithm (알고리즘)

알고리즘은 주어진 문제를 해결하기 위한 단계적인 절차나 방법을 의미합니다.



### ※ Algorithm Transparency (알고리즘 투명성)

알고리즘 의 결정에 영향을 미치는 요소들이 해당 알고리즘을 사용하는 시스템을 사용하고, 규제하고, 그 영향을 받는 사람들에게 가시적이거나 투명해야 한다는 원칙



### ※ ANN (인공 신경망)

ANN은 "Artificial Neural Network"의 약어로, 인공 신경망을 의미합니다. 인공 신경망은 인간의 신경 시스템에서 영감을 받아 디자인된 컴퓨터 알고리즘입니다.



### ※ Apache Spark (아파치 스파크)

Apache Spark는 대규모 데이터를 분산 처리하는 프레임워크입니다.



### ※ API (Application Programming Interface, 응용 프로그래밍 인터페이스)

API는 Application Programming Interface의 약자로 컴퓨터나 컴퓨터 프로그램 사이의 연결로서 인터페이스를 구축하거나 사용하는 방법을 의미합니다.



### ※ ArtPrompt (아트프롬프트)

ArtPrompt는 LLM이 ASCII 아트를 효율적으로 해석하지 못하는 취약점을 공격하는 방법이다.



### ※ ASR (자동 음성 인식)

ASR은 Automatic Speech Recognition의 약자로 자동 음성 인식 기술로 사람의 음성을 컴퓨터가 인식하고 이를 텍스트나 명령어등으로 변환하는 기술을 의미합니다.



### ※ Augmented Intelligence (증강지능)

사람이 할 수 있는 문맥 이해, 연관성, 의사 결정 등의 능력과 컴퓨터의 장점인 데이터 처리 능력을 적절하게 합쳐 최대한 활용하는 인공지능



### ※ Autoencoders ( 오토 인코더)

오토 인코더는 차원 축소 및 특징 학습에 사용되는 비지도 학습 신경망의 한 유형



### ※ Autonomous Agent (자율 에이전트)

자기 스스로 목표를 설정하고, 계획하고, 실행하면서 외부의 개입 없이 작업을 수행하는 AI 시스템.



## ［ B ］



### ※ Backpropagation (역전파)

역전파는 인공 신경망에서 가중치와 편향을 조절해 나가면서 학습을 하는 알고리즘의 하나이며 인공신경망을 출력층부터 입력층까지 오차를 역으로 전파하며 학습해 나가는 방식을 의미합니다.



### ※ Batch Size (배치 사이즈)

Batch Size는 하나의 데이터셋을 여러 작은 그룹으로 나누었을때 하나의 소그룹에 속하는 데이터 수를 의미합니다.



### ※ Bayesian Networks (베이지안 네트워크)

베이지안 네트워크는 불확실한 지식을 표현하고 추론하는 데 사용되는 일종의 확률 그래픽 모델



### ※ Bayesian theorem (베이즈의 정리)

**베이즈 정리 (Bayes' Theorem)**는 확률론에서 조건부 확률을 계산하는 기본적인 공식 중 하나.



### ※ Bias (편향)

알고리즘에 내재된 편향으로 인한 오류 가능성



### ※ Big Data (빅데이터)

빅데이터는 통상적으로 사용되는 데이터의 양과 다르게 수용 한계를 넘어서는 크기의 데이터, 즉 방대한 양의 데이터를 의미합니다.



### ※ Bitbucket (비트버킷)

깃 버전 관리 시스템을 사용하는 소스 코드 및 개발 프로젝트를 대상으로 한 아틀라시안 소유의 웹 기반 버전 관리 저장소 호스팅 서비스입니다.



### ※ Black Box Model (블랙박스 모델)

블랙박스 모델은 내부 메커니즘을 명확하게 이해할 수 없고 내부 프로세스가 숨겨져 있어 모델이 어떻게 답을 내놓는지 알기 어려운 모델



## ［ C ］



### ※ Capsule Networks ( 캡슐 네트워크)

캡슐네트워크는 특징 간의 공간적 관계를 인코딩하여 일반화 및 견고성을 향상시킴으로써 컨볼루션 신경망(CNN)의 일부 한계를 해결하는 것을  목표로 하는 신경망 아키텍처의 한 유형



### ※ CCaaS (Contact Center as a Service)

클라우드 기반의 컨택센터 솔루션



### ※ Chain of Thought (CoT)

AI가 정답을 곧바로 말하지 않고 “생각의 과정을 단계적으로 풀어가도록 유도하는 기법.



### ※ Chatbot (챗봇)

챗봇(Chatbot)은 문자 또는 음성 대화를 통해 사용자와 상호작용하도록 설계된 컴퓨터 프로그램 또는 인공지능 에이전트



### ※ Clustering (클러스터링)

클러스터링은 데이터가 주어졌을 때 데이터들의 특징의 따라 서로 비슷한 데이터들끼리 묶어서 분류하는 것을 의미합니다.



### ※ CNN (합성곱 신경망)

CNN(합성곱 신경망)은 딥러닝의 한 종류로, 주로 이미지 인식과 컴퓨터 비전 작업에 사용되는 신경망 구조입니다. 

CNN은 특히 이미지 처리에 특화되어 있으며, 이미지 내의 패턴과 특징을 자동으로 학습하여 분류, 감지, 분할 등의 작업을 수행할 수 있습니다.



### ※ CodeHS (코드에이치에스)

학생들이 컴퓨터 과학과 프로그래밍을 배울 수 있도록 도와주는 온라인 학습 플랫폼입니다.



### ※ CodePen (코드펜)

CodePen은 온라인 코드 편집기 및 공유 플랫폼으로, HTML, CSS, JavaScript 등의 웹 기술을 사용하여 코드를 작성하고 실행할 수 있습니다.



### ※ Codewars (코드워즈)

컴퓨터 프로그래밍을 위한 교육 커뮤니티입니다. 플랫폼에서 소프트웨어 개발자는 kata로 알려진 프로그래밍 문제에 대해 교육합니다.



### ※ Cognitive Computing (인지 컴퓨팅)

인지 컴퓨팅(Cognitive Computing)은 사람의 인지 능력을 컴퓨터 시스템에 적용하여 활용하는 기술.



### ※ Compiler (컴파일러)

컴파일러는 프로그래밍 언어로 작성된 소스코드를 기계어로 바꾸어주는 프로그램을 의미합니다.



### ※ Computer Vision (컴퓨터 비전)

컴퓨터비전은 AI의 한 분야로, 컴퓨터가 이미지, 비디오등의 시각적 데이터들을 이해하고 활용하는 기술들을 의미합니다.



### ※ Contact Center (컨택 센터)

고객과 기업이 다양한 채널을 통해 커뮤니케이션할 수 있는 시설이나 시스템



### ※ Context Windows (컨텍스트 창)

모델이 한 번에 고려하거나 '기억'할 수 있는 토큰 단위의 텍스트 양. 토큰은 평균적으로 단어의 3/4 크기.



### ※ Conversational AI (대화형 인공지능)

사람과 자연어(natural language)로 대화를 나눌 수 있는 인공지능 기술.



### ※ Conversational Interface (대화형 인터페이스)

대화형 인터페이스(Conversational Interface)는 사용자가 마치 사람과 대화하듯이 자연스러운 언어(음성 또는 텍스트)를 사용하여 소프트웨어, 

애플리케이션 또는 장치와 상호 작용할 수 있도록 설계된 사용자 인터페이스(UI)의 한 형태



### ※ Corpus (말뭉치)

언어 연구를 위해 텍스트를 컴퓨터가 읽을 수 있는 형태로 모아 놓은 언어 자료



### ※ Crawler (크롤러)

크롤러는 인터넷 상에서 웹 페이지를 수집하는 컴퓨터 프로그램으로서 일반적으로 검색 엔진과 같은 정보 검색 시스템에 사용됩니다.



### ※ Creative Commons (크리에이티브 커먼즈)

CC(Creative Commons)는 저작권자가 자신의 저작물을 자유롭게 공유할 수 있도록 도와주는 저작권 라이선스입니다.



### ※ Cross-validation (교차 검증)

데이터를 여러 번 나누어 모델을 평가하는 방법



### ※ CUDA (쿠다)

CUDA는 Compute Unified Device Architecture의 약자로, NVIDIA가 개발한 GPGPU 기술이다.



### ※ Curse of Dimensionality (차원의 저주)

차원의 저주는 데이터의 차원이 증가할수록 학습에 필요한 데이터의 양이 기하급수적으로 늘어나는 현상



### ※ Cybersecurity (사이버 보안)

사이버 보안(Cybersecurity)은 컴퓨터 시스템, 네트워크, 하드웨어, 소프트웨어 및 디지털 데이터를 사이버 위협으로부터 보호하는 모든 기술, 프로세스 및 관행



## ［ D ］



### ※ Data Augmentation (데이터 증강)

Data Augmentation(데이터 증강)은 기존 데이터를 인위적으로 늘려서 더 많은 학습 데이터를 만들어내는 기법

### 

데이터 정제는 분석이나 머신러닝 모델링에 사용하기 전에 데이터의 오류, 누락, 중복, 불일치 등을 정리하고 정돈하는 과정



### ※ Data Mining (데이터 마이닝)

데이터 마이닝은 대규모의 데이터에서 사용자가 원하는 특정 데이터를 추출하는 것을 의미합니다.



### ※ Data Preprocessing (데이터 전처리)

데이터 전처리는 머신러닝 모델에 입력할 훈련 데이터를 컴퓨터가 좀 더 편하게 이해할 수 있도록 데이터를 편집하는 과정을 의미합니다.



### ※ Decision Tree (결정 나무)

결정나무(Decision Tree)는 지도학습 방식에 속하는 머신러닝 알고리즘으로, 분류와 회귀 문제 해결에 적용됩니다. 

이 알고리즘은 입력 데이터와 해당 출력을 분석하여 데이터 간의 패턴을 학습합니다. 

그 후, 학습된 패턴을 기반으로 트리 구조의 규칙 모델을 생성합니다. 

이 트리 구조는 각 노드에서 정의된 규칙을 통해 데이터를 분할함으로써 분류나 회귀 문제를 해결하는 알고리즘입니다. 

다른 머신러닝 알고리즘과 달리 설명이 가능한 머신러닝 방법입니다.



### ※ Decoder (디코더)

디코더는 인코더에서 압축된 정보를 이용해 새로운 정보를 생성하는데 사용되는 신경망 모델의 한 종류를 의미합니다.



### ※ Deepfake (딥페이크 )

딥페이크는 심층 학습(Deep Learning)과 가짜(Fake)의 결합어로, 인공지능 기술을 활용하여 사람의 목소리, 얼굴, 또는 다른 신체 부위를 

현실감 있게 합성하는 기술을 지칭합니다. 



### ※ Deep Learning (딥러닝)

인간이 가지고 있는 뉴런과 비슷한 형태의 인공신경망 방식으로 데이터를 처리하여 학습하는 방식을 의미합니다.



### ※ Diffusion model (확산 모델)

점진적으로 잡음을 제거하면서 점차적으로 데이터를 개선해 나가는 방식으로, 특히 이미지 생성에 유용하게 사용된다.



### ※ Digital Convergence (디지털 컨버전스)

기술, 산업, 매체 간의 경계가 허물어지면서 다양한 디지털 기술, 서비스, 산업이 하나로 합쳐지는 현상



### ※ Dimensionality Reduction (차원 축소)

차원 축소(Dimensionality Reduction)는 주어진 데이터 세트의 중요한 속성을 유지하면서 더 적은 수의 특징(차원)을 사용하여 데이터를 표현하는 방법



### ※ Distillation (증류)

대규모 AI 모델의 지식을 더 작은 모델로 전달하는 기술



### ※  Distributed Machine Learning (분산 머신 러닝)

분산 머신 러닝(Distributed Machine Learning)은 여러 대의 컴퓨터 또는 장치를 사용하여 대규모 데이터 세트를 처리하는 기술.



### ※ DNN (Deep Neural Network, 심층 신경망)

DNN (Deep Neural Network)은 심층 신경망이라고도 불리며, 여러 개의 은닉층으로 구성된 인공 신경망



## ［ E ］



### ※ Early Stopping (조기종료)

모델을 끝까지 훈련하면 과대접합이 발생하기 때문에 훈련 손실이 최소값에 도달하기 전에 훈련을 중단하는 기법



### ※ Edge Computing (엣지 컴퓨팅)

Edge Computing(엣지 컴퓨팅)은 데이터가 생성되는 네트워크의 가장자리(Edge) 가까이에서 데이터를 처리하고 분석하는 분산 컴퓨팅 모델



### ※ Embedding (임베딩)

기계 학습(ML) 및 인공 지능(AI) 시스템이 인간처럼 복잡한 지식 영역을 이해하는 데 사용하는 실제 객체를 수치로 표현한 것



### ※ Encoder (인코더)

인코더는 입력 데이터를 압축하고 요약하는데 사용되는 신경망 모델의 한 종류를 의미합니다.



### ※ Ensemble Learning (앙상블 학습)

앙상블 학습은 예측의 정확성과 견고성을 개선하기 위해 여러 모델을 결합하는 기계 학습 기술. 앙상블 학습은 이미지 분류, 음성 인식 및 금융 모델링과 같은 애플리케이션에 사용.



### ※ Epoch (에포크)

Epoch는 AI모델이 학습 데이터셋을 가지고 몇번이나 학습을 할것인지를 지정해주는 파라미터 값을 의미합니다.



### ※ Ethical AI maturity model (윤리적 AI 성숙도 모델)

AI 기술을 사용하는데 있어 윤리적 관행을 평가하고 개선하며 신뢰할 수 있는 방법을 제시하는 모델



### ※ Exobrain (엑소브레인)

한국형 인공지능(AI: Artificial Intelligence)으로 엑소브레인이라는 명칭은 '인간 몸 바깥의 뇌'라는 뜻이다.



### ※ Explainable AI (XAI)

Explainable AI (XAI) 또는 설명 가능한 인공지능은 인공지능(AI) 시스템이 내린 결정이나 수행한 행동에 대해 인간이 이해할 수 있는 명확하고 일관된 설명을 제공할 수 있는 능력



## ［ F ］



### ※ Fairness (페어니스)

페어니스는 AI가 편견 없이 공정하게 작동하는 것을 의미



### ※ Feature Engineering (피처 엔지니어링)

피처 엔지니어링은 데이터로 모델을 트레이닝시키는 데 사용되는 머신 러닝 알고리즘의 성능을 향상하기 위해 데이터를 변환하고 개선하는 프로세스입니다.



### ※ Feature Extraction (특징 추출)

특징추출은 머신러닝 알고리즘에 사용할 데이터 세트에서 가장 중요한 부분을 식별하고 분리하는 프로세스



### ※ Federated Learning (페더레이티드 러닝)

중앙 서버에 데이터를 모으지 않고 각 기기에서 학습된 모델을 결합하여 전체 모델을 개선하는 기술



### ※ Few-shot Learning (FSL)

소량의 데이터로도 새로운 작업을 수행할 수 있도록 학습하는 방식



### ※ Filter Bubble (필터 버블)

필터 버블(Filter Bubble)은 인터넷 사용자에게 맞춤형 정보만 제공하는 알고리즘으로 인해 사용자가 자신의 기존 신념과 선호도에 부합하는 정보만 접하게 되고, 

다양한 관점이나 반대되는 의견에는 노출되지 않는 현상



### ※ Fine-tuning (미세 조정)

미세 조정(Fine-tuning)은 사전 학습된 AI 모델에 풀고자 하는 문제에 맞는 학습 데이터 수백, 수천 개를 추가로 마련해서 대규모 언어 모델을

다시 학습시켜 모델의 파라미터를 업데이트하는 것을 의미.



### ※ Foundation Model (파운데이션 모델)

광범위한 사용 사례에 적용할 수 있도록 광범위한 데이터에 대해 훈련된 기계 학습 또는 딥 러닝 모델



### ※ Frontier Models (프론티어 모델)

프론티어 모델은 AI의 경계를 확장하며 다양한 작업을 수행할 수 있는 대규모 시스템



### ※ Fuzzy Logic (퍼지 논리)

퍼지 논리는 추론의 부정확성과 불확실성을 허용하는 논리 유형. 퍼지 논리는 제어 시스템, 의사 결정 및 패턴 인식과 같은 애플리케이션에 사용됩니다.



## ［ G ］



### ※ GAN (Generative Adversarial Network, 적대적 생성 신경망)

GAN은 Generative Adversarial Network의 약자로 적대적 생성 신경망이라고도 불리며 실제에 가까운 이미지나 사람이 쓴 것과 같은 글 등 

여러 가짜 데이터들을 생성할 수 있는 AI기술을 의미합니다.



### ※ Gemini (제미나이)

제미나이는 Google DeepMind가 개발하고 2023년 12월 7일에 공개한 대규모 언어 모델(LLM)입니다. 이 모델에는 GPT-3.5와 유사한 성능을 

제공하는 일반 제미나이(GEMINI) 모델과 GPT-4와 비슷한 수준의 성능을 갖춘 제미나이 어드밴스드(GEMINI ADVANCED) 모델이 있습니다."



### ※ Gemma (젬마)

Gemma는 Google의 자체 대규모 언어 모델(Gemini)의 경량화된 오픈소스 버전입니다.



### ※ Generative AI (생성형 인공지능)

Generative AI (생성형 인공지능)은 기존의 데이터로부터 학습하여 텍스트, 이미지, 오디오, 비디오, 코드 등 새롭고 독창적인 콘텐츠를 생성할 수 있는 인공지능의 한 분야



### ※ Genetic Algorithms (유전 알고리즘)

유전 알고리즘은 자연 선택 과정에서 영감을 받은 일종의 기계 학습 알고리즘



### ※ GitHub (깃허브)

깃허브는 루비 온 레일스로 작성된 분산 버전 관리 툴인 깃 저장소 호스팅을 지원하는 웹 서비스입니다.



### ※ GitLab (깃랩)

깃랩은 깃랩 사가 개발한 깃 저장소 및 CI/CD, 이슈 추적, 보안성 테스트 등의 기능을 갖춘 웹 기반의 데브옵스 플랫폼으로써, 

오픈 소스 라이선스 및 사유 소프트웨어 라이선스를 사용한다.



### ※ GNN (Graph Neural Network, 그래프 신경망)

관계와 연결을 파악하여 사회적 네트워크를 분석하는 "사회학자" 같은 신경망.



### ※ gorilla problem (고릴라 문제)

고릴라 문제는 초지능 인공지능(AGI)이 인간을 압도하고 통제력을 상실하게 될 위험을 경고하는 문제



### ※ GPT (Generative Pre-trained Transformer)

미리 학습된 대형 언어 모델을 사용하여 텍스트를 생성하는 AI 기술



### ※ Gradient (기울기)

gradient란 벡터 공간에서 스칼라 함수의 최대 증가율을 나타내는 벡터이다. 기본적으로, gradient는 어떤 점에서 함수의 값이 가장 빠르게 증가하는 방향과 그 증가율을 표시.



### ※ Gradient Descent (경사하강법)

경사하강법은 함수의 기울기를 구하고 경사의 반대 방향으로 계속 이동시켜 기울기를 0에 수렴할때까지 반복하는 것을 의미합니다.



### ※ Gradient Vanishing (기울기 소실)

역전파를 이용해 학습을 진행하게 되면 학습이 진행됨에따라 가충치를 넘겨주며 학습을 진행시키게 되는데 이때 이 가중치가 점점 감소하기 시작하며 

결국 소실되어버려 학습이 불가능하게 되는것을 의미합니다.



### ※ Grounding (현실 연결)

AI 모델을 신뢰할 수 있는 정보 소스에 연결해 검증된 데이터를 기반으로 결과물을 생성하는 과정



### ※ GPGPU (General-Purpose Computing on Graphics Processing Units, 지피지피유)

GPGPU는 General-Purpose Computing on Graphics Processing Units의 약어로, 기존의 GPU를 활용하여 컴퓨터 그래픽스 처리를 넘어서 

CPU가 전통적으로 담당해온 일반 연산 작업을 수행하는 기술이다.



### ※ GPT (Generative Pretrained Transformer)

GPT는 Generative Pretrained Transformer의 약자로 Open AI에서 개발한 대형 언어 모델로서 기존의 여러 인공지능 모델과 달리 대규모 자연어 데이터를 

사전학습한 후 다양한 자연어 처리 태스크에 대해 Fine-Tuning을 통해 최적화하는 방식으로 학습되어있는 자연어처리 모델을 의미합니다.



### ※ GPU (Graphics processing unit)

GPU는 AI 소프트웨어를 구성하는 그래픽 가속 담당 칩으로 높은 성능의 하드웨어를 요구하는 AI에 필수로 있어야 하는 장치



### ※ GRU (Gated Recurrent Unit, 게이트 순환 유닛)

"Gated Recurrent Unit"의 약자로, LSTM과 마찬가지로 장기적인 의존성을 학습할 수 있는 순환 신경망의 한 종류입니다. 

LSTM과 비슷한 기능을 수행하지만, 더 간단한 구조를 가지고 있어 계산적으로 효율적입니다.

GRU는 LSTM의 게이트 메커니즘을 일부 단순화하여 구현됩니다.



### ※ GTC (GPU Technology Conference, GPU 태크놀로지 컨퍼런스)

GTC(GPU Technology Conference)는 AI, 컴퓨터 그래픽, 데이터 사이언스 등 다양한 분야에 초점을 맞춘 컨퍼런스로, Nvidia에서 주최합니다. 

이 행사는 개발자, 연구원, 기술자들이 GPU 기술 및 그 이상의 분야에서의 혁신을 공유하고 탐색하는 컨퍼런스이다.



## ［ H ］



### ※ HackerRank (해커랭크)

HackerRank는 온라인 코딩 플랫폼으로, 프로그래밍과 알고리즘 문제를 해결하고 테스트할 수 있습니다. 다양한 프로그래밍 언어와 도메인에 대한 문제들이 제공되며, 학습자들은 솔루션을 공유하고 비교할 수 있습니다. 코딩 인터뷰 연습과 스킬 향상을 위한 도구로 활용됩니다.



### ※ Hallucination (환각)

챗GPT와 같은 인공지능(AI) 언어 모델에서 '할루시네이션'은 주어진 데이터 또는 맥락에 근거하지 않은 잘못된 정보나 허위 정보를 생성하는 것을 뜻함.



### ※ Heuristic Search (휴리스틱 검색)

휴리스틱 검색은 지름길이나 경험 법칙을 사용하여 신속하게 해결책을 찾거나 의사 결정을 내리는 문제 해결 방법



### ※ Hidden Layer (은닉층)

은닉층은 입력층과 출력층 사이에 존재하는 하나의 층으로써 신경망의 외부에서는 이 계층의 노드들에게 직접 접근할 수 없으며 실질적으로 데이터를 

가지고 계산을 하는 층을 의미합니다.



### ※ Hidden Markov Model (HMM, 은닉 마르코프 모델)

Hidden Markov Model (HMM)은 관찰 가능한 사건들의 시퀀스를 모델링하는 데 사용되는 통계적 모델



### ※ HITL (Human In The Loop)

신뢰도 높은 학습 모델을 도출하기 위해 인공지능 시스템 등에 사람이 개입하여 시스템과 사람이 상호작용하는 학습구조



### ※ Hugging Face (허깅페이스)

Hugging Face, Inc.는 기계 학습을 사용하여 애플리케이션을 구축하기 위한 도구를 개발하는 미국 회사입니다.



### ※ HyperCLOVA X (하이퍼클로바 X)

네이버에서 구축한 자연어 생성 모델로, GPT-3와 유사하지만 학습 데이터 중 한국어 비중이 97%에 달하는, 한국어에 최적화한 언어 모델입니다.



### ※ Hyperparameter (하이퍼 파라미터)

기계학습(머신러닝)이나 딥러닝 모델을 학습시키기 전에 사용자가 직접 설정해야 하는 값들



### ※ Hyperparameter Tuning (하이퍼파라미터 튜닝)

하이퍼파라미터 튜닝 (Hyperparameter Tuning)은 머신러닝 모델의 성능을 최적화하기 위해 모델 학습 전에 사용자가 직접 설정하는 파라미터인 

하이퍼파라미터의 최적 조합을 찾는 과정



### ※ Hyper-scale AI (초거대 인공지능)

천문학적인 개수의 파라미터를 가지는 인공신경망 모델을 기반으로 복잡한 문제를 해결하는 인공지능 모델.



## ［ I ］



### ※ Inference (인퍼런스)

인공 지능(AI) 및 기계 학습(ML) 분야에서 훈련된 모델이 새로운 데이터에 대해 결론을 도출하는 과정



### ※ Input Layer (입력층)

입력층은 들어온 신호를 아무런 연산없이 그대로 다음 노드에 보내주는 다리의 역활을 하는 층을 의미합니다.



### ※ Intelligent Agent (지능형 에이전트)

Intelligent Agent(지능형 에이전트)는 주어진 환경을 인식하고, 목표를 달성하기 위해 자율적으로 행동하며, 학습 능력을 통해 성능을 향상시킬 수 있는 컴퓨터 시스템



### ※ Intelligent Tutoring Systems (ITS, 지능형 튜터 시스템)

Intelligent Tutoring Systems(ITS, 지능형 튜터링 시스템)은 AI를 이용해서 학생 개개인에게 맞춤형 학습을 제공하는 교육 시스템



### ※ IPCC (IP Contact Center)

인터넷 프로토콜(IP) 기반의 컨택센터



## ［ J ］



### ※ Jailbreaking (탈옥)

AI 모델에 설정된 안전 장치나 윤리적 가이드라인을 우회하여, 본래 허용되지 않은 행동을 하도록 만드는 과정



### ※ Jailbreak Prompt (탈옥 프롬프트)

Jailbreak Prompt는 LLM의 내부 보안 체계를 우회시켜 유해한 내용을 생성하도록 만드는 프롬프트 기법이다.



## ［ K ］



### ※ Keras (케라스)

Theano와 Tensorflow 기반의 딥러닝용 고차원 라이브러리입니다.



### ※ K-Nearest neighbors (K-최근접 이웃 알고리즘)

AI 학습 알고리즘의 종류중 하나로, 가장 가까운 이웃 샘플을 찾고 이 샘플들의 타깃 값을 평균하여 예측



### ※ Knowledge Graph (지식 그래프)

지식 그래프(Knowlege Graph)는 개체, 사건 또는 개념과 같은 실체에 대한 상호 연결된 설명 모음



### ※ Knowledge Representation (지식 표현)

지식표현이란 지식과 정보를 기계가 쉽게 이해하고 문제 해결과 의사 결정에 활용할 수 있는 방식으로 표현, 구성, 조작하는 것을 다루는 인공 지능 분야.



## ［ L ］



### ※ LAM (Large Action Moded, 대규모 행동 모델)

사용자의 의도와 행동 패턴을 학습하여 인간의 행동을 추론하는 모델



### ※ LangChain (랭체인)

LangChain은 대규모 언어 모델(Large Language Models, LLMs)을 기반으로 강력한 애플리케이션을 구축하기 위한 오픈 소스 프레임워크



### ※ LangChain Libraries (랭체인 라이브러리)

LangChain은 하나의 거대한 라이브러리가 아니라, 대규모 언어 모델(LLM)을 활용하는 강력한 애플리케이션을 만들기 위해 서로 연결된 여러 개의 라이브러리로 구성된 프레임워크



### ※ LangChain Templates (랭체인 템플릿)

LangChain Templates은 반복적인 작업을 쉽게 처리할 수 있는 미리 정의된 템플릿



### ※ LangServe (랭서브)

LangChain을 사용하여 만든 LLM 기반 애플리케이션의 핵심 로직을 웹 서비스 형태로 만들어 다른 애플리케이션이나 시스템에서 쉽게 접근하고 사용할 수 있도록 도와주는 도구



### ※ LangSmith (랭스미스)

LangSmith는 LangChain 프레임워크를 사용하여 구축된 AI 애플리케이션, 특히 대규모 언어 모델(LLM)을 활용하는 애플리케이션의 개발, 테스트, 디버깅 및 모니터링을 위한 

통합 플랫폼



### ※ Large-Scale AI (초거대 AI)

대규모 데이터와 복잡한 모델 구조를 사용하여 훈련된 인공지능.

딥러닝 기법의 인공신경망 중 수십억 개 이상의 파라미터(매개변수)를 가지고 있으며, 스스로 학습 및 사고, 판단할 수 있는 인간의 뇌 구조를 

모방하여 인간의 언어와 이미지, 영상 등의 데이터를 이해하고 생성하는 능력이 매우 뛰어남.



### ※ Lightweighting (경량화)

경량화는 딥러닝 모델의 단점인 많은 메모리 공간의 필요를 줄이고자 고안된 방법으로서 모델에서 중요한 가중치들만 선별하거나 가중치의 비트값을 

줄여 모델의 메모리 사이즈를 줄여주는 방법을 의미합니다.



### ※ Linear Regression (선형 회귀)

선형 회귀(Linear Regression)는 종속 변수(Dependent Variable)와 하나 이상의 독립 변수(Independent Variable) 간의 선형 관계를 모델링하는 통계적 방법



### ※ LLM (Large Language Model, 거대 언어 모델)

LLM은 Large Language Model의 약어다. 엄청나게 많은 텍스트 데이터를 학습한 AI 모델



### ※ LMM (Large Multimodal Model)

텍스트, 이미지, 오디오, 비디오와 같은 다양한 데이터 유형 또는 모달리티로부터 정보를 이해하고 생성할 수 있는 고급 인공지능 시스템.



### ※ Local AI (On Device AI)

개별 장치(컴퓨터, 스마트 폰 등)에 내장되어 사용하는 AI

### 

### ※ Logistic Regression (로지스틱 회귀)

로지스틱 회귀(Logistic Regression)는 종속 변수가 범주형(Categorical)일 때, 즉 특정 클래스에 속할 확률을 예측하는 데 사용되는 통계적 모델



### ※ LOMO (적은메모리 최적화)

LOMO(LOw Memory Optimization)는 LLM을 파인튜닝하는데 필요한 메모리 요구량을 줄여주는 기술이다.



### ※ Loss Function (손실함수)

손실함수는 인공신경망에서 학습데이터의 예측값과 실제값의 차이를 계산하여 오차를 나타내는 함수를 의미합니다.



### ※ LPU (언어처리 장치)

LPU(Language Processing Unit)은 Groq사가 개발한 LLM 추론하는데 특화된 연산 장치이다.



### ※ LSTM (장단기 메모리)

"Long Short-Term Memory"의 약자로, 장기적인 의존성을 학습할 수 있는 순환 신경망의 한 종류입니다. LSTM은 시계열 데이터나 문장 등과 같이 

순서가 있는 데이터에서 효과적으로 작동하는데, 특히 장기적인 의존성을 가진 데이터에서 기존의 순환 신경망 모델보다 우수한 성능을 보입니다.



## ［ M ］



### ※ Machine Learning (머신러닝)

컴퓨터가 학습하여 인공지능의 성능을 향상 시키는 기술들을 통틀어서 말하는것을 의미합니다.



### ※ Machine-to-Machine Communication (사물 간 통신)

사물 간 통신은 기기와 기기 간에 데이터를 주고받는 기술. 



### ※ Markov Decision Process (MDP, 마르코프 결정 과정)

마르코프 결정 과정(Markov Decision Process, MDP)은 순차적인 의사 결정 문제를 수학적으로 모델링하는 프레임워크



### ※ Matplotlib (맷플롯리브)

"Matlab"과 "plotting"의 조합으로 이루어진 단어로, Matlab은 과학 및 엔지니어링 분야에서 널리 사용되는 상용 소프트웨어이며, 

matplotlib는 Matlab의 그래프 기능을 모방하여 파이썬에서 데이터 시각화를 가능하게 하는 라이브러리입니다.



### ※ MDN Web Docs (MDN 웹 문서)

MDN Web Docs는 Mozilla Developer Network Web 문서의 약자로, 웹 개발자를 위한 온라인 문서 리소스입니다.



### ※ MLOps (Machine Learning Operations, 기계학습 운영)

MLOps(Machine Learning Operations)는 기계학습(ML)의 절차와 학습된 모델의 배포를 자동화하고 단순화하는 과정



### ※ Model Compression (모델 압축)

딥러닝 모델의 크기(파라미터 수, 연산량 등)를 줄이면서도 성능은 최대한 유지하려는 기술



### ※ Model Evaluation (모델 평가)

모델 평가 (Model Evaluation)는 구축한 머신러닝 모델의 성능을 측정하고, 그 결과를 바탕으로 모델의 품질을 판단하는 과정



### ※ Model Generalization (모델 일반화)

Model Generalization(모델 일반화)은 AI나 머신러닝 모델이 학습한 데이터뿐만 아니라, 보지 못한 새로운 데이터에서도 잘 작동하는 능력.



### ※ Model Overfitting (모델 과적합)

모델 과적합 (Model Overfitting)은 머신러닝 모델이 학습 데이터에는 지나치게 잘 맞지만, 실제 새로운 데이터(테스트 데이터 또는 실전 데이터)에는 

제대로 일반화하지 못하는 현상을 의미



### ※ MoE (Mixture of Experts, 전문가 믹스)

MoE(Mixture of Experts)는 각 단어에서 알 수 있듯이 '전문가의 혼합'이라는 뜻을 가지고 있으며 여러 '전문가' 모델 중 문제에 적절한 일부 모델만을 선택해서 사용하는 구조



### ※ Moravec's Paradox (모라벨의 역설)

사람에게는 너무나 쉬운 것이 컴퓨터에게는 어렵다는 의미



### ※ Multi-Agent Systems (다중 에이전트 시스템)

다중 에이전트 시스템은 여러 지능형 에이전트가 상호 작용하고 협력하여 공동의 목표를 달성하거나 작업을 수행하는 시스템을 설계하고 구현하는 데 중점을 두는 인공 지능 영역



### ※ Multimodal (멀티모달)

텍스트, 이미지, 음성, 영상 등 여러 종류의 데이터를 동시에 이해하고 처리할 수 있는 능력



### ※ Multiple Linear regression (MLR, 다중 선형 회귀)

다중 선형 회귀(Multiple Linear Regression)는 두 개 이상의 독립 변수(Independent Variables) 와 하나의 종속 변수(Dependent Variable) 사이의 

관계를 모델링하는 통계적 기법



## ［ N ］



### ※ Neural Network (인공신경망)

인공신경망은 사람 뇌의 뉴런 구조에서 영감을 받아 만든 컴퓨터 알고리즘으로 데이터를 보고 패턴을 학습하고 예측하는 모델.

입력층-은닉층-출력층으로 이루어져 있습니다.



### ※ NLP (Natural Language Processing, 자연어처리)

자연어처리는 Natural Language Processing의 약자로 인간의 언어를 컴퓨터와 같은 기계들이 이해하고 활용할 수 있도록 하는 인공지능의 주요 분야중 하나.



### ※ Node (노드)

노드는 인공신경망에서 입력층, 은닉층, 출력층을 구성하는 요소들을 의미합니다.



### ※ Novelty Detection (새로운 것 탐지)

Novelty Detection (새로운 것 탐지)은 학습 데이터셋에 존재하지 않던 새롭고 이전에 보지 못했던 패턴이나 데이터를 식별하는 것을 목표



### ※ NPU (Neural Processing Unit)(인공신경망 처리 장치)

인공신경망 연산에 특화된 하드웨어. 온디바이스 AI 성능 향상에 기여합니다.



### ※ NumPy (Numerical Python, 넘파이)

Numerical Python의 약자로, Python에서 사용되는 배열을 다루는 라이브러리입니다.



## ［ O ］



### ※ On-Device AI (온디바이스 AI)

클라우드 서버 연결 없이 기기 자체에서 인공지능 연산을 수행하는 기술. 개인 정보 보호 강화, 빠른 응답 속도 등의 장점이 있습니다.



### ※ One-Hot Encoding (원-핫 인코딩)

One-Hot Encoding (원-핫 인코딩)은 범주형(Categorical) 데이터를 머신러닝 모델이 이해하고 처리할 수 있는 숫자 형식으로 변환하는 방법 중 하나



### ※ One-Hot Vector (원-핫 벡터)

원-핫 벡터는 범주형 데이터를 처리하는 방법으로 데이터중 자기자신만을 1 나머지를 0인 벡터로 바꾸어 정리하는 방법을 의미합니다.



### ※ Ontology (온톨로지)

온톨로지(Ontology)란 사람들이 세상에 대하여 보고 듣고 느끼고 생각하는 것에 대하여 서로 간의 토론을 통하여 합의를 이룬 바를, 개념적이고 

컴퓨터에서 다룰 수 있는 형태로 표현한 모델로, 개념의 타입이나 사용상의 제약조건들을 명시적으로 정의한 기술



### ※ OpenAI

OpenAI는 안전하고 인류에게 유익한 인공지능(AI)을 개발하는 것을 목표로 하는 미국의 AI 연구소



### ※ OpenCV (Open Source Computer Vision, 컴퓨터 비전 오픈 소스)

Open Source Computer Vision의 약어로 실시간 컴퓨터 비전을 처리하는 목적으로 만들어진 라이브러리이며 실시간 이미지 프로세싱에 중점을 둔다.

컴퓨터 비전이란 컴퓨터를 이용하여 이미지 또는 동영상에서 데이터를 추출하는 분야 혹은 학문이다.



### ※ Optimization (최적화)

최적화는 모델이 가장 좋은 성능을 내도록 파라미터 값을 조정하는 과정을 의미합니다.



### ※ Orchestration (조정)

여러 개의 컴퓨터 시스템, 애플리케이션 및 서비스를 조율하고 관리하는 것으로 여러 개의 작업을 함께 연결하여 크기가 큰 워크플로나 프로세스를 실행하는 방식



### ※ Outlier Detection (이상치 탐지)

Outlier Detection(이상치 탐지)은 주어진 데이터 집합에서 대부분의 데이터와 뚜렷하게 다른 데이터 점, 객체 또는 사건을 식별하는 프로세스



### ※ Output Layer (출력층)

출력층은 은닉층에서 연산이 끝난 데이터를 은닉층에서 데이터를 받고 이를 출력하는 층을 의미합니다.

출력층은 인공 신경망에서 최종적인 출력 값을 생성하는 계층입니다.



### ※ Overfitting (과적합)

주어진 하나의 데이터셋만을 가지고 너무 과하게 학습을 시킬경우 모델이 해당 데이터셋에 맞춰 극단적으로 변해버려 다른 데이터셋에 대해 

정확도가 많이 낮아져 버리는것을 의미합니다.



## ［ P ］



### ※ Padding (패딩)

패딩은 데이터를 압축하는 과정중에서 데이터가 유실되거나 손상되는 것을 예방하기위해 데이터의 외각에 특정 값(대체로 0을 사용함)을 부여하는 과정을 의미합니다.



### ※ Pandas (팬더스)

"Panel Data"의 약자로, 파이썬에서 구조화된 데이터를 쉽게 조작하고 처리할 수 있는 도구를 제공하며 데이터 조작과 분석을 위한 강력한 라이브러리입니다.



### ※ Parameter (파라미터)

모델이 학습을 통해 조정하는 숫자값들.



### ※ Pattern Recognition (패턴인식)

패턴인식은 딥러닝과 인공지능 기술들을 활용하여 이미지, 음성, 텍스트등의 패턴을 자동으로 인식하고 분류하는 기술을 의미합니다.



### ※ Perceptron (퍼셉트론)

퍼셉트론은 인간의 뇌의 신경망 구조를 본떠 그물망 형태로 노드들을 연결하여 사람의 뇌처럼 동작 하게 하는 최초의 인공신경망을 의미합니다.



### ※ Pipelining (파이프 라이닝)

파이프 라이닝은 여러 작업을 순차적으로 수행하도록 설계된 컴퓨팅 방식으로, 입출력중에 데이터셋을 처리하는 단계를 병렬로 처리하여 처리시간을 단축하는 방법입니다.



### ※ Plug-in (플러그인)

생성형 AI가 확장된 기능을 보여 줄 수 있도록 추가적인 기능을 제공하는 컴포넌트를 말 함



### ※ Predictive Learning (예측 분석)

예측 분석은 과거의 데이터셋을 분석하고 이를 바탕으로 미래의 결과를 예측할 수 있는 하나의 기술을 의미합니다.



### ※ Pre-Training (프리트레이닝)

Pre-Training은 AI가 실무를 하기 전에 많은 데이터를 먼저 학습 하는 단계이다. 이 단계를 통해 AI는 언어와 이미지 같은 데이터에서 기본적인 패턴을 학습하게 됩니다.



### ※ Private AI (프라이빗 AI)

개인 정보나 민감한 데이터를 보호하면서 인공지능을 활용하는 기술 또는 개념



### ※ Prompt (프롬프트)

프롬프트는 어떤 일을 하도록 촉구하는 말이나 행동을 말합니다. 좁은 의미의 프롬프트는 모델로부터 응답을 생성하기 위해 입력하는 텍스트 혹은 문장을 의미합니다.



### ※ Prompt Engineering (프롬프트 엔지니어링)

LLM(대형 언어 모델)을 잘 활용하기 위해 어떤 질문(프롬프트)을 어떻게 짜느냐에 집중하는 기술. 쉽게 말하면 **“AI에게 말을 잘 시켜서, 원하는 대답을 얻어내는 기술”**



### ※ Public AI (퍼블릭 AI)

Public AI는 공공의 이익을 위해 공공 자금으로 개발되고 관리되는 인공지능 생태계를 의미



### ※ PyPI (Python Package Index, 파이썬 패키지 인덱스)

PyPI, Python Package Index의 약자입니다. PyPI는 파이썬 패키지 저장소로서, 파이썬 개발자들이 패키지를 공유하고 관리하는 곳입니다.



### ※ PyTorch (파이토치)

파이썬(Python) 기반의 오픈 소스 머신러닝 라이브러리로, 페이스북 인공지능 연구집단에 의해 개발되었습니다.



## ［ Q ］



### ※ Quantization (양자화)

양자화 (Quantization)는 머신러닝 모델, 특히 딥러닝 모델의 크기를 줄이고 연산 속도를 향상시키기 위해 모델의 파라미터(가중치, 활성화 함수)를 

더 낮은 정밀도의 데이터 형식으로 변환하는 기술



### ※ Query (쿼리)

쿼리는 데이터베이스에서 데이터를 검색하거나 조작하기위한 명령어나 질의문을 의미합니다.



## ［ R ］



### ※ RAG (Retrieval-Augmented Generation, 검색 증강 생성)

RAG(Retrieval-Augmented Generation)는 생성형 AI 시스템이 외부 지식 저장소를 활용해 보다 정확하고 사용자의 의도에 부합하는 결과를 제공하는 기술 접근 방법이다. 

이 방식은 AI가 내부 학습 데이터 만을 사용하지 않고 필요한 지식을 실시간으로 검색하여 통합함으로써 출력의 질을 높이는 방법이다.



### ※ Random Forest (랜덤 포레스트)

랜덤 포레스트는 결정 나무를 기반으로 한 앙상블 머신러닝 기법입니다. 이 방법은 단일 결정 나무의 주요 단점인 과적합을 완화하고, 

모델의 정확도를 향상시키기 위해 여러 개의 결정 나무를 사용하는 방법이다.



### ※ Ray (레이)

Ray는 AI 애플리케이션 및 파이썬 프로그램을 쉽게 확장할 수 있도록 설계된 프레임워크입니다. 

이를 통해 개발자들은 다중 CPU나 GPU를 이용하여 대규모 병렬 처리와 분산 컴퓨팅 작업을 간편하게 수행할 수 있다.



### ※ ReadWorks (리드웍스)

ReadWorks는 읽기와 이해력을 향상시키기 위해 고안된, 교육 분야에서 널리 사용되는 온라인 리딩 및 문학 이해 프로그램입니다.



### ※ Reasoning (추론)

문제를 해결하기 위한 전반적인 논리적 사고 과정



### ※ Recognition (객체 인식)

객체 인식은 이미지나 비디오에서 객체를 식별하는 기술로, 객체 검출과 유사하지만, 검출된 객체가 어떤 종류인지 분류하는 과정까지 포함한다는 차이가 있습니다.



### ※ Regression Analysis (회귀 분석)

Regression Analysis(회귀 분석)은 하나 이상의 독립 변수(X)가 종속 변수(Y)에 어떤 영향을 미치는지를 분석하고 예측하는 통계 기법



### ※ Regularization (모델 규제)

이 기법은 모델을 더 간단하고 단순하게 만드는 방법



### ※ Reinforcement Learning (강화 학습)

강화 학습은 모델이 주변 환경과 여러 상호작용을 하며 경험을 쌓아나가면서 보상을 최대화 하고 비용을 최소화 하기위해 시행착오를 통하여 스스로 학습해 나가는 것을 의미



### ※ RLHF (Reinforcement Learning from Human Feedback, 인간 피드백을 통한 강화 학습)

Reinforcement Learning from Human Feedback (RLHF)는 강화 학습(Reinforcement Learning, RL)의 한 종류로, 명시적인 보상 함수(reward function) 대신 

인간의 피드백을 활용하여 에이전트(agent)를 학습시키는 방법



### ※ Repl.it (리플릿)

리플릿은 사용자들이 브라우저를 사용하여 코드를 작성하고 앱과 웹사이트를 만들 수 있게 합니다.



### ※ Responsible AI (책임감 있는 AI)

AI 시스템이 윤리적으로 개발되고 사용되게 할 책임이 AI 배포 책임자에게 있음을 의미



### ※ RNN (Recurrent Neural Network, 순환 신경망)

"Recurrent Neural Network"의 약자로, 시퀀스 데이터(Sequence Data)를 처리하는 데 사용되는 신경망입니다. 

시퀀스 데이터는 순서가 있는 데이터로, 예를 들어 문장, 음성, 주식 가격 등이 시퀀스 데이터의 예입니다.



### ※ Robotics (로보틱스)

Robotics (로보틱스)는 인간이 수행하는 작업을 수행하도록 프로그래밍할 수 있는 기계인 로봇의 설계, 구축, 작동 및 사용을 다루는 공학 및 과학의 학문 분야



### ※ RPA (Robotic Process Automation, 로보틱 프로세스 자동화)

RPA는 소프트웨어 로봇을 사용하여 반복적이고 규칙적인 업무를 자동화하는 기술.



## ［ S ］



### ※ Scikit-learn (Scientific Kit for Machine Learning, 사이킷런)

"Scientific Kit for Machine Learning"의 줄임말로, 과학적인 기계 학습을 위한 도구 모음을 의미한다.



### ※ SciPy (사이파이)

파이썬을 기반으로 하여 과학, 분석, 그리고 엔지니어링을 위한 과학(계산)적 컴퓨팅 영역의 여러 기본적인 작업을 위한 라이브러리입니다.



### ※ Self-supervised Learning (자가 학습)

자가 학습은 레이블 없는 데이터에서 스스로 학습 과제를 만들어 학습하는 방법



### ※ Sentiment Analysis (감정 분석)

Sentiment Analysis(감정 분석 또는 감성 분석)는 텍스트 안에 담긴 사람의 감정이나 의견, 태도를 파악하는 기술



### ※ Semantic Search (시맨틱 검색)

시맨틱 검색(Semantic Search)은 단순히 검색어와 문자가 일치하는 콘텐츠를 찾는 게 아니라, 검색어와 문장의 의미를 파악하여 그에 상응하는 콘텐츠를 찾아내는 기술입니다. 

사용자의 질문을 분석하고 해석해 검색 결과의 품질을 올리는 기술이다.



### ※ Semantic Web (시맨틱 웹)

시맨틱 웹은 컴퓨터가 인간이 이해하는 정보를 이해하고 처리하여 웹 상의 정보를 보다 효과적으로 관리하고 활용할 수 있도록 하는 기술



### ※ Semi-Supervised Learning (준지도 학습)

준지도 학습은 레이블이 지정된 데이터와 레이블이 지정되지 않은 데이터의 조합에 대해 모델을 교육하는 기계 학습 유형



### ※ Seq2Seq (Sequence-to-Sequence Models, 시퀀스 투 시퀀스)

시퀀스 투 시퀀스 모델은 기계 번역이나 텍스트 요약과 같이 입력 시퀀스를 출력 시퀀스에 매핑하는 작업에 사용되는 딥러닝 모델 클래스입니다.



### ※ Sentiment Analysis (감성분석)

감성분석이란 텍스트에 들어있는 의견이나 감성, 평가, 태도 등의 주관적인 정보를 컴퓨터가 분석해 이해하는 기술을 의미합니다. 



### ※ Simple Linear regression (단순 선형 회귀)

단순 선형 회귀(Simple Linear Regression)는 통계학 및 머신러닝에서 하나의 독립 변수(Independent Variable)와 

하나의 종속 변수(Dependent Variable) 사이의 관계를 모델링하는 가장 기본적인 회귀 분석 방법



### ※ SLM (Small Language Model, 소규모 언어 모델)

자연어 콘텐츠를 처리, 이해 및 생성할 수 있는 AI 모델.  소규모 언어 모델은 대규모 모델보다 더 컴팩트하고 효율적.



### ※ SLLM (Small Large Language Model, 거대 언어 모델(LLM)보다 작은 규모의 대형 언어 모델)

Small Large Language Model (Small LLM)은 이름 그대로, 기존의 거대 언어 모델(Large Language Model, LLM)에 비해 파라미터 수가 적고 

모델 크기가 작은 언어 모델을 의미.



### ※ Sololearn (솔로런)

Sololearn은 모바일 및 웹 기반의 온라인 프로그래밍 학습 플랫폼입니다. 이는 초보자부터 전문가까지 다양한 수준의 개발자를 대상으로 하며, 

다양한 프로그래밍 언어와 기술에 대한 학습 리소스와 커뮤니티 기능을 제공합니다.



### ※ SourceForge (소스포지)

소스포지(SourceForge)는 오픈 소스 소프트웨어(Open Source Software, OSS) 개발 프로젝트를 위한 웹 기반의 중앙 집중식 플랫폼



### ※ STT (Speech To Text, 줄임말 음성 텍스트 변환)

STT는 Speech To Text의 줄임말로 음성을 텍스트로 변환해 주는 기술. 



### ※ Stack Overflow (스택 오버플로)

스택 익스체인지 네트워크의 대표적인 웹사이트로, 2008년 제프 앳우드와 조엘 스폴스키가 만든 엑스퍼츠-익스체인지와 같은 초기 Q&A에 비해 더 개방적인 웹사이트입니다.



### ※ Strucured Data (정형 데이터)

정형 데이터는 테이블 형식의 데이터로써 일정한 형식을 갖춘 데이터로, 데이터베이스나 엑셀 시트와 같은 표 형태를 띄는 데이터를 의미합니다.



### ※ Supervised Learning (지도 학습)

지도 학습은 모델에게 학습 데이터를 줄때 정답도 같이 알려주어 학습 데이터셋들과 함께 학습시키는 방법을 의미합니다.



### ※ SVM (Support Vector Machines, 서포트 벡터 머신)

서포트 벡터 머신은 분류 및 회귀 분석에 사용되는 기계 학습 알고리즘 유형. 서포트 벡터 머신은 이미지 인식, 텍스트 분류 및 생물정보학과 같은 애플리케이션에 사용.



### ※ Swarm Intelligence (군집 지능)

군집지능은 개미나 벌과 같은 사회적 곤충의 집단 행동에서 영감을 얻은 인공 지능의 한 형태로, 개별 에이전트 간의 상호 작용에서 집단의 지능이 나타납니다.



## ［ T ］



### ※ Technology Adoption (기술 도입 또는 기술 채택 )

개인, 조직, 또는 사회가 새로운 기술을 수용, 채택, 통합하고 사용하는 과정을 의미



### ※ Tensor (텐서)

텐서는 다차원 배열로, 컴퓨터 비전 분야에서 벡터, 행렬과 같은 개념들의 일반화된 형태로, 여러 개의 축을 갖고 있습니다.



### ※ TensorFlow (텐서플로)

구글AI 상하의 딥러닝 팀인 구글브레인이 2011년에 개발을 시작하여 2015년에 오픈 소스로 공개한 기계학습 라이브러리입니다.



### ※ Theano (테아노)

주로 수치 계산과 심볼릭 계산을 수행하는 데 사용되는 과학 계산을 위한 오픈 소스 라이브러리입니다. 



### ※ Time-LLM (타임 엘엘엠)

LLM을 재 프로그래밍(학습)을 해서 시계열 예측이 가능하게 LLM을 튜닝한 모델이다.

TIME-LLM은 시계열 데이터를 기호 기반 인코딩, 패턴 기반 인코딩, 자연어 인코딩 등의 다양한 방식을 통해 텍스트 형태로 변환합니다. 

이 변환된 데이터를 대규모 언어 모델(Large Language Models, LLM)에 학습시켜 사용함으로써, LLM이 시계열 데이터를 이해하고 예측할 수 있게 합니다.



### ※ Token (토큰)

토큰은 자연어처리에서 문장을 단어 혹은 구두점 등을 기준으로 나눈 작은 단어의 단위를 의미합니다.



### ※ Tokenization (토큰화)

토큰화는 입력받은 문장을 모델이 이해할 수 있도록 토큰으로 바꾸어 분리 및 정렬하는 작업을 의미합니다.



### ※ Transfer Learning (전이학습)

전이학습은 기존에 학습된 모델을 불러와 또 다른 데이터셋을 넣어주어 모델을 추가로 학습시켜 모델의 성능을 짧은 시간에 올릴 수 있는 학습방법을 의미합니다.



### ※ Transformer (트랜스포머)

트랜스포머는 구글에서 발표한 인코더-디코더 모델의 일종으로, 자연어 처리 분야에서 최근 가장 인기있고 널리 사용되고있는 강력한 자연어처리 모델중 하나입니다.



### ※ TTFT (Time To First Token)

첫 번째 토큰(단어나 문자)이 생성되기까지 걸리는 시간.



### ※ Tuning (튜닝)

튜닝(Tuning)은 어떤 시스템이나 모델의 성능을 최적화하기 위해 파라미터나 설정을 조정하는 과정을 의미



## ［ U ］



### ※ UDOP (범용문서처리)

UDOP(Universal Document Processing)의 약자이며 2023년 마이크로소프트가 제안한 문서를 이해하고 문서의 내용을 이해하고 그걸 바탕으로 답변을 생성하는 모델이다.



### ※ Unlearning (학습 취소법)

"Unlearning(학습취소법)은 LLM이 이미 학습한 지식을 잊도록 하는 방법이다. 이 기법은 LLM 개발자가 저작권을 위반하는 내용이나 해로운 내용을 제거할 때 사용할 수 있다.



### ※ Unstrucured Data (비정형 데이터)

비정형 데이터는 표 형태가 아닌 다양한 형식으로 구성된 데이터로써 주로 텍스트, 이미지, 음성, 동영상등의 형태를 가지고있는 데이터를 의미합니다.



### ※ Unsupervised Learning (비지도 학습)

비지도학습은 학습 데이터셋을 모델에게 전달해 줄때 정답을 알려주지 않고 학습 데이터셋만 넘겨주어 모델이 직접 판단하게 하는 학습방법을 의미합니다.



### ※ Unsupervised Pre-training (비지도 사전 학습)

Unsupervised Pre-training (비지도 사전 학습)은 머신러닝 모델을 학습시키는 한 가지 방법으로, 레이블이 없는 대량의 데이터를 사용하여 모델이 데이터의 기본적인 특징(feature)이나 표현(representation)을 먼저 학습하도록 하는 것



## ［ V ］



### ※ VAE (Variational Autoencoder, 변이형 오토인코더)

VAE (Variational Autoencoder)는 생성 모델(Generative Model)의 한 종류로, 입력 데이터의 확률 분포(probability distribution)를 학습하여 

새로운 데이터를 생성하는 심층 신경망 모델



### ※ Vector Database (벡터 데이터베이스)

데이터를 “숫자 벡터(숫자 배열)”로 저장하고, 비슷한 걸 빠르게 찾아주는 DB



### ※ Vectorization (벡터화)

데이터를 효율적으로 다루기 위해 숫자로 변환하는 과정을 말합니다.



### ※ Virtual Assistant (가상 비서)

Virtual Assistant (가상 비서)는 사용자의 음성 또는 텍스트 명령을 이해하고, 다양한 작업을 수행하여 사용자를 돕는 소프트웨어 기반의 지능형 에이전트



### ※ Voice Cloning (보이스 클로닝)

AI가 특정 사람의 목소리를 듣고 학습한 뒤, 그 목소리로 전혀 다른 텍스트를 자연스럽게 읽도록 만드는 기술.



## ［ W ］



### ※ Weight (가중치)

뉴럴 네트워크(인공신경망) 안에서 학습되는 숫자 값. 이 숫자들이 입력값의 중요도를 결정하고 결국 출력값을 바꾸는 역할을 합니다.



### ※ Weight Explosion (가중치 폭주)

역전파를 이용해 학습을 진행하게 되면 학습이 진행됨에따라 가충치를 넘겨주며 학습을 진행시키게 되는데 이때 가중치가 점점 증가하다 결국 비정상적으로 

증가해버려 학습에 방해가 되어버리는 경우를 의미합니다.



### ※ Word Embedding (워드 임베딩)

워드 임베딩(Word Embedding)은 단어를 벡터 형태로 표현하는 방법.

워드 임베딩은 단어 간의 유사성을 수치적으로 표현할 수 있어 자연어 처리 모델의 성능을 향상시킵니다.



## ［ X ］



### ※ XAI (Explainable Artificial Intelligence, 설명 가능한 인공지능)

인공지능(AI)의 한 부류인 "설명 가능한 인공지능(Explainable AI 또는 XAI)"은 기계 학습 모델의 예측을 해석하고 이해하기 쉽게 설명하는 기술을 의미합니다. 

XAI는 특히 복잡한 딥 러닝 모델과 같은 블랙박스 모델의 결과를 이해하고 신뢰할 수 있도록 도와줍니다.



## ［ Z ］



### ※ Zero-shot Learning (제로샷 러닝)

한 번도 본 적 없는 문제나 클래스를 훈련 없이 바로 풀어내는 능력
